{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from data_split import createTrainValSplit\n",
    "\n",
    "DATA_DIR = '/Data/folder/with' # data folder which is divided into the classes as folders\n",
    "VAL_SPLIT = 0.2 #add how much you want to split your data in validation and training\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VALID_DIR = os.path.join(DATA_DIR, 'val')\n",
    "SIZE = (224, 224)\n",
    "BATCH_SIZE = 12\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #splits your data into train and validation\n",
    "    createTrainValSplit(DATA_DIR,VAL_SPLIT)\n",
    "    \n",
    "    num_train_samples = sum([len(files) for r, d, files in os.walk(TRAIN_DIR)])\n",
    "    num_valid_samples = sum([len(files) for r, d, files in os.walk(VALID_DIR)])\n",
    "\n",
    "    num_train_steps = math.floor(num_train_samples/BATCH_SIZE)\n",
    "    num_valid_steps = math.floor(num_valid_samples/BATCH_SIZE)\n",
    "    \n",
    "    #data augment to make your data better representation of the population\n",
    "    gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "    val_gen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "    batches = gen.flow_from_directory(TRAIN_DIR, target_size=SIZE, class_mode='categorical', shuffle=True, batch_size=BATCH_SIZE)\n",
    "    val_batches = val_gen.flow_from_directory(VALID_DIR, target_size=SIZE, class_mode='categorical', shuffle=True, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    #load model from keras pre given libraries\n",
    "    model = keras.applications.resnet50.ResNet50()\n",
    "\n",
    "    classes = list(iter(batches.class_indices))\n",
    "    \n",
    "    #remove the last layer\n",
    "    model.layers.pop()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "    last = model.layers[-1].output\n",
    "    x = Dense(len(classes), activation=\"softmax\")(last)\n",
    "    finetuned_model = Model(model.input, x)\n",
    "    finetuned_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    for c in batches.class_indices:\n",
    "        classes[batches.class_indices[c]] = c\n",
    "    finetuned_model.classes = classes\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "    checkpointer = ModelCheckpoint('resnet50_best.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "    finetuned_model.fit_generator(batches, steps_per_epoch=num_train_steps, epochs=1000, callbacks=[early_stopping, checkpointer], validation_data=val_batches, validation_steps=num_valid_steps)\n",
    "    finetuned_model.save('resnet50_final.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
